{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b10615cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01_data_quality_check.ipynb\n",
    "#importing required libraries/modules\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb4aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating File Path\n",
    "DATA_DIR = os.path.join(\"..\", \"data\", \"raw\")\n",
    "FILE_NAME = \"Banglore_traffic_dataset.csv\"  \n",
    "\n",
    "\n",
    "file_path = os.path.join(DATA_DIR, FILE_NAME)\n",
    "print(\"Loading file from:\", file_path)\n",
    "\n",
    "#Error Handling\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"File not found at: {file_path}\")\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Shape (rows, columns):\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad409acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# – High-level summary & missing values \n",
    "\n",
    "# Summary stats for numeric columns\n",
    "\n",
    "df.describe().T  \n",
    "\n",
    "# Missing value percentage per column\n",
    "\n",
    "missing_summary = (\n",
    "    df.isna()    #boolean values are cast to True=>1 and False => 0. mean is calculated to find total missing values per total actual values.\n",
    "      .mean()\n",
    "      .sort_values(ascending=False)\n",
    "      .to_frame(name=\"missing_pct\")\n",
    ")\n",
    "\n",
    "missing_summary[\"missing_pct\"] = (missing_summary[\"missing_pct\"] * 100).round(2)\n",
    "missing_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a23608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#– Duplicate checks\n",
    "# Total duplicate rows\n",
    "total_dupes = df.duplicated().sum()\n",
    "\n",
    "print(f\"Total fully-duplicated rows: {total_dupes}\")\n",
    "\n",
    "dup_pct = (total_dupes / len(df) * 100) if len(df) > 0 else 0 \n",
    "print(f\"Duplicate row percentage: {dup_pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7314383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic value sanity (numeric columns)\n",
    "numeric_cols=df.select_dtypes(include=['int64','float64']).columns.to_list()\n",
    "\n",
    "dq_numeric = []\n",
    "\n",
    "for col in numeric_cols:\n",
    "    series = df[col]\n",
    "    dq_numeric.append({\n",
    "        \"column\": col,\n",
    "        \"dtype\": str(series.dtype),\n",
    "        \"min\": series.min(),\n",
    "        \"q1\": series.quantile(0.25),\n",
    "        \"median\": series.median(),\n",
    "        \"q3\": series.quantile(0.75),\n",
    "        \"max\": series.max(),\n",
    "        \"n_missing\": series.isna().sum()\n",
    "    })\n",
    "pd.DataFrame(dq_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc88acc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Configuration Dictionary of columns(grouping columns of similar data type)\n",
    "\n",
    "COLUMNS = {\n",
    "    \"timestamp\": \"Date\",         \n",
    "    \"speed\": \"Average Speed\",             \n",
    "    \"volume\": \"Traffic Volume\",      \n",
    "    \"location\": ['Area Name', 'Road/Intersection Name'],          \n",
    "    \"lat\": \"latitude\",                \n",
    "    \"lon\": \"longitude\",              \n",
    "}\n",
    "COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3688a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#– Parse timestamps \n",
    "time_col = COLUMNS.get(\"timestamp\", None)  #having a fallback value 'None'\n",
    "\n",
    "if time_col and time_col in df.columns:\n",
    "    df[time_col] = pd.to_datetime(df[time_col], errors=\"coerce\")\n",
    "    \n",
    " # Check how many became NaT (failed parsing)\n",
    "    bad_ts = df[time_col].isna().sum()\n",
    "    print(f\"Failed to parse {bad_ts} timestamps out of {len(df)} rows.\")\n",
    "    \n",
    "#     # Extract useful time parts\n",
    "    df[\"hour\"] = df[time_col].dt.hour\n",
    "    df[\"dayofweek\"] = df[time_col].dt.dayofweek\n",
    "    df[\"date\"] = df[time_col].dt.date\n",
    "else:\n",
    "    print(\"No valid timestamp column configured. Update COLUMNS['timestamp'].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c49d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#– Check speed & volume sanity\n",
    "speed_col = COLUMNS.get(\"speed\", None)\n",
    "vol_col = COLUMNS.get(\"volume\", None)\n",
    "\n",
    "if speed_col and speed_col in df.columns:\n",
    "    print(\"Speed distribution summary:\")\n",
    "    print(df[speed_col].describe())\n",
    "    \n",
    "    # Possible anomaly checks \n",
    "    n_negative_speed = (df[speed_col] < 0).sum()\n",
    "    n_too_high_speed = (df[speed_col] > 150).sum()   # assuming >150 km/h is unrealistic\n",
    "    \n",
    "    print(f\"\\nNegative speed values: {n_negative_speed}\")\n",
    "    print(f\"Speed >150 km/h: {n_too_high_speed}\")\n",
    "else:\n",
    "    print(\"Speed column not configured / not found.\")\n",
    "\n",
    "\n",
    "if vol_col and vol_col in df.columns:\n",
    "    print(\"\\nVolume distribution summary:\")\n",
    "    print(df[vol_col].describe())\n",
    "    \n",
    "    n_negative_vol = (df[vol_col] < 0).sum()\n",
    "    print(f\"\\nNegative traffic volume values: {n_negative_vol}\")\n",
    "else:\n",
    "    print(\"Volume column not configured / not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3401e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geo sanity\n",
    "lat_col = COLUMNS.get(\"lat\", None)\n",
    "lon_col = COLUMNS.get(\"lon\", None)\n",
    "\n",
    "if lat_col in df.columns and lon_col in df.columns:\n",
    "    print(\"Latitude summary:\")\n",
    "    print(df[lat_col].describe())\n",
    "\n",
    "    print(\"\\nLongitude summary:\")\n",
    "    print(df[lon_col].describe())\n",
    "    \n",
    "    # Bengaluru rough bounds (approx)\n",
    "    lat_min, lat_max = 12.7, 13.2\n",
    "    lon_min, lon_max = 77.4, 77.9\n",
    "    \n",
    "    out_of_bounds = df[ (df[lat_col] < lat_min) | (df[lat_col] > lat_max) |(df[lon_col] < lon_min) | (df[lon_col] > lon_max)]\n",
    "    print(f\"\\nPoints outside Bengaluru bounding box: {len(out_of_bounds)}\")\n",
    "else:\n",
    "    print(\"No lat/lon columns configured. Skipping geo sanity checks.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
