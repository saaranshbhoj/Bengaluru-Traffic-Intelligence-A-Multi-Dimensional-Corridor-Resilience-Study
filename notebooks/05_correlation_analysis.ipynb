{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa34018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Correlation Analysis of Weather type with other Parameters:\n",
    "from sqlalchemy import create_engine\n",
    "password_db='Bsa1986%40%21'\n",
    "database_name='bengaluru_traffic'\n",
    "host_port='127.0.0.1:3306'\n",
    "\n",
    "\n",
    "engine=create_engine(f'mysql+pymysql://root:{password_db}@{host_port}/{database_name}')\n",
    "query=\"\"\"\n",
    "SELECT \n",
    "    *\n",
    "FROM traffic_cleaned_geo;\n",
    "\"\"\"\n",
    "\n",
    "df=pd.read_sql_query(query,engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b915632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Analysis of Overall city vs individual corridors of weather types with key metrics.\n",
    "weather_dummies=pd.get_dummies(df['weather'],prefix='weather_') #One Hot Encoding converting strings into binary equivalent.\n",
    "metrics=['traffic_volume','avg_speed','road_capacity_utilization','congestion_score','incident_reports','environmental_impact','ped_cycle_count','parking_usage','public_transport_usage']\n",
    "\n",
    "#Concat all relevant df for correlation analysis per corridor\n",
    "df_encoded=pd.concat([df[['area','road']], df[metrics], weather_dummies],axis=1)\n",
    "\n",
    "#Storing the base_metric categories for extraction of relevant df\n",
    "weather_list=[col for col in df_encoded.columns if 'weather_' in col]\n",
    "\n",
    "#Calculating the Overall City correlations:\n",
    "global_corr=df_encoded[weather_list+metrics].corr(method='pearson').round(3).loc[weather_list,metrics]\n",
    "\n",
    "#Extracting total corridors for step by step iteration\n",
    "corridors=df_encoded.groupby(['area','road'])\n",
    "results=[] #Store the correlation matrix having measurable deviations\n",
    "\n",
    "#Iteration per corridor:\n",
    "for (area,road),group in corridors:\n",
    "    local_corr=group[weather_list+metrics].corr(method='pearson').round(3).loc[weather_list,metrics]\n",
    "\n",
    "    #Calculating any sizeable deviation\n",
    "    deviation=local_corr-global_corr\n",
    "    if abs(deviation).max().max()>0.12:\n",
    "        results.append({'area':area,'road':road,'deviation':deviation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe4e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To represent them into a Dataframe we need to convert them into 1-d from current 2-d shape using stack() function\n",
    "df_list=[]\n",
    "\n",
    "for item in results:\n",
    "    area=item['area']\n",
    "    road=item['road']\n",
    "\n",
    "    #Stackking of the results in matrix(2-d) form\n",
    "    matrix=item['deviation']\n",
    "\n",
    "    df_mid=matrix.stack().reset_index()\n",
    "    df_mid.columns=['weather_type','metric','deviation']\n",
    "    df_mid['area']=area\n",
    "    df_mid['road']=road\n",
    "\n",
    "    df_list.append(df_mid)\n",
    "\n",
    "#Final DataFrame using Concat Function\n",
    "df_final=pd.concat(df_list,ignore_index=True)\n",
    "\n",
    "#Extract deviations that are significant\n",
    "df_final=df_final[df_final['deviation'].abs()>0.12]\n",
    "df_final.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3209198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation analysis of incident_reports of overall city and corridor-wise analysis.\n",
    "metrics=['traffic_volume','avg_speed','road_capacity_utilization','congestion_score','environmental_impact','ped_cycle_count','parking_usage','public_transport_usage']\n",
    "base_metric=['incident_reports']\n",
    "\n",
    "#Concat all relevant df for correlation analysis per corridor\n",
    "df_encoded=pd.concat([df[['area','road']], df[metrics+base_metric]],axis=1)\n",
    "\n",
    "#Calculating the Overall City correlations:\n",
    "global_corr=df_encoded[base_metric+metrics].corr(method='spearman').round(3).loc[base_metric,metrics]\n",
    "\n",
    "#Extracting total corridors for step by step iteration\n",
    "corridors=df_encoded.groupby(['area','road'])\n",
    "results=[] #Store the correlation matrix having measurable deviations\n",
    "\n",
    "#Iteration per corridor:\n",
    "for (area,road),group in corridors:\n",
    "    local_corr=group[base_metric+metrics].corr(method='spearman').round(3).loc[base_metric,metrics]\n",
    "\n",
    "    #Calculating any sizeable deviation\n",
    "    deviation=local_corr-global_corr\n",
    "    if abs(deviation).max().max()>0.12:\n",
    "        results.append({'area':area,'road':road,'deviation':deviation})\n",
    "global_corr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f65c65f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_reports</th>\n",
       "      <th>metric</th>\n",
       "      <th>deviation</th>\n",
       "      <th>area</th>\n",
       "      <th>road</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>incident_reports</td>\n",
       "      <td>road_capacity_utilization</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>Electronic City</td>\n",
       "      <td>Hosur Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>incident_reports</td>\n",
       "      <td>congestion_score</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>Electronic City</td>\n",
       "      <td>Hosur Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>incident_reports</td>\n",
       "      <td>road_capacity_utilization</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>Electronic City</td>\n",
       "      <td>Silk Board Junction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>incident_reports</td>\n",
       "      <td>congestion_score</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>Electronic City</td>\n",
       "      <td>Silk Board Junction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>incident_reports</td>\n",
       "      <td>congestion_score</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>Indiranagar</td>\n",
       "      <td>Cmh Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>incident_reports</td>\n",
       "      <td>traffic_volume</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>Koramangala</td>\n",
       "      <td>Sarjapur Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>incident_reports</td>\n",
       "      <td>environmental_impact</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>Koramangala</td>\n",
       "      <td>Sarjapur Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>incident_reports</td>\n",
       "      <td>ped_cycle_count</td>\n",
       "      <td>0.184</td>\n",
       "      <td>Koramangala</td>\n",
       "      <td>Sarjapur Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>incident_reports</td>\n",
       "      <td>traffic_volume</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>Koramangala</td>\n",
       "      <td>Sony World Junction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>incident_reports</td>\n",
       "      <td>environmental_impact</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>Koramangala</td>\n",
       "      <td>Sony World Junction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>incident_reports</td>\n",
       "      <td>traffic_volume</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>M.G. Road</td>\n",
       "      <td>Anil Kumble Circle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>incident_reports</td>\n",
       "      <td>road_capacity_utilization</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>M.G. Road</td>\n",
       "      <td>Anil Kumble Circle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>incident_reports</td>\n",
       "      <td>congestion_score</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>M.G. Road</td>\n",
       "      <td>Anil Kumble Circle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>incident_reports</td>\n",
       "      <td>environmental_impact</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>M.G. Road</td>\n",
       "      <td>Anil Kumble Circle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>incident_reports</td>\n",
       "      <td>traffic_volume</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>M.G. Road</td>\n",
       "      <td>Trinity Circle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>incident_reports</td>\n",
       "      <td>environmental_impact</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>M.G. Road</td>\n",
       "      <td>Trinity Circle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>incident_reports</td>\n",
       "      <td>ped_cycle_count</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>Yeshwanthpur</td>\n",
       "      <td>Yeshwanthpur Circle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    incident_reports                     metric  deviation             area  \\\n",
       "0   incident_reports  road_capacity_utilization     -0.169  Electronic City   \n",
       "1   incident_reports           congestion_score     -0.185  Electronic City   \n",
       "2   incident_reports  road_capacity_utilization     -0.217  Electronic City   \n",
       "3   incident_reports           congestion_score     -0.173  Electronic City   \n",
       "4   incident_reports           congestion_score     -0.162      Indiranagar   \n",
       "5   incident_reports             traffic_volume     -0.189      Koramangala   \n",
       "6   incident_reports       environmental_impact     -0.189      Koramangala   \n",
       "7   incident_reports            ped_cycle_count      0.184      Koramangala   \n",
       "8   incident_reports             traffic_volume     -0.260      Koramangala   \n",
       "9   incident_reports       environmental_impact     -0.260      Koramangala   \n",
       "10  incident_reports             traffic_volume     -0.274        M.G. Road   \n",
       "11  incident_reports  road_capacity_utilization     -0.154        M.G. Road   \n",
       "12  incident_reports           congestion_score     -0.177        M.G. Road   \n",
       "13  incident_reports       environmental_impact     -0.274        M.G. Road   \n",
       "14  incident_reports             traffic_volume     -0.214        M.G. Road   \n",
       "15  incident_reports       environmental_impact     -0.214        M.G. Road   \n",
       "16  incident_reports            ped_cycle_count     -0.165     Yeshwanthpur   \n",
       "\n",
       "                   road  \n",
       "0            Hosur Road  \n",
       "1            Hosur Road  \n",
       "2   Silk Board Junction  \n",
       "3   Silk Board Junction  \n",
       "4              Cmh Road  \n",
       "5         Sarjapur Road  \n",
       "6         Sarjapur Road  \n",
       "7         Sarjapur Road  \n",
       "8   Sony World Junction  \n",
       "9   Sony World Junction  \n",
       "10   Anil Kumble Circle  \n",
       "11   Anil Kumble Circle  \n",
       "12   Anil Kumble Circle  \n",
       "13   Anil Kumble Circle  \n",
       "14       Trinity Circle  \n",
       "15       Trinity Circle  \n",
       "16  Yeshwanthpur Circle  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To represent them into a Dataframe we need to convert them into 1-d from current 2-d shape using stack() function\n",
    "df_list=[]\n",
    "\n",
    "for item in results:\n",
    "    area=item['area']\n",
    "    road=item['road']\n",
    "\n",
    "    #Stackking of the results in matrix(2-d) form\n",
    "    matrix=item['deviation']\n",
    "\n",
    "    df_mid=matrix.stack().reset_index()\n",
    "    df_mid.columns=['incident_reports','metric','deviation']\n",
    "    df_mid['area']=area\n",
    "    df_mid['road']=road\n",
    "\n",
    "    df_list.append(df_mid)\n",
    "\n",
    "#Final DataFrame using Concat Function\n",
    "df_final=pd.concat(df_list,ignore_index=True)\n",
    "\n",
    "#Extract deviations that are significant\n",
    "df_final=df_final[df_final['deviation'].abs()>0.15]\n",
    "df_final.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baae64cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Analysis of Mobility(ped_cycle_count) with other key metrics for the overall city and individual corridors and their sizeable deviation.\n",
    "base_metric=['ped_cycle_count']\n",
    "metrics=['traffic_volume','congestion_score','road_capacity_utilization','avg_speed','incident_reports','environmental_impact','parking_usage','public_transport_usage','traffic_signal_compliance']\n",
    "\n",
    "#Concatening required columns\n",
    "df_encoded=pd.concat([df[['area','road']], df[base_metric+metrics]],axis=1) #concatenation should happen horizontally\n",
    "\n",
    "#Calculating the Global Correlations\n",
    "global_corr=df_encoded[base_metric+metrics].corr(method='spearman').round(3).loc[base_metric,metrics]\n",
    "\n",
    "corridors=df_encoded.groupby(['area','road'])\n",
    "results=[]\n",
    "\n",
    "#iteration every corridor:\n",
    "for (area,road),group in corridors:\n",
    "    local_corr=group[base_metric+metrics].corr(method='spearman').round(3).loc[base_metric,metrics]\n",
    "\n",
    "    #Calculating significant deviations\n",
    "    deviation=local_corr-global_corr\n",
    "    if abs(deviation).max().max() > 0.15:\n",
    "        results.append({\n",
    "            'area':area,\n",
    "            'road':road,\n",
    "            'deviation':deviation})\n",
    "global_corr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a48528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ingestion into a DataFrame by stacking the matrix results\n",
    "final_list=[]\n",
    "\n",
    "for item in results:\n",
    "    area=item['area']\n",
    "    road=item['road']\n",
    "    matrix=item['deviation']\n",
    "\n",
    "    #Stacking the matrix results\n",
    "    df_mid=matrix.stack().reset_index()\n",
    "    df_mid.columns=['Mobility','metric','deviation']\n",
    "    df_mid['area']=area\n",
    "    df_mid['road']=road\n",
    "\n",
    "    final_list.append(df_mid) #small dfs appending to a list\n",
    "\n",
    "#Final concatenation into single DataFrame:\n",
    "df_final=pd.concat(final_list)\n",
    "df_final=df_final[df_final['deviation'].abs() > 0.15]\n",
    "df_final.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7577363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation of Environmental Impact City vs corridor\n",
    "base_metric=['environmental_impact']\n",
    "metrics=['traffic_volume','congestion_score','road_capacity_utilization','avg_speed','incident_reports','ped_cycle_count','parking_usage','public_transport_usage','traffic_signal_compliance']\n",
    "\n",
    "#Concatening required columns\n",
    "df_encoded=pd.concat([df[['area','road']], df[base_metric+metrics]],axis=1) #concatenation should happen horizontally\n",
    "\n",
    "#Calculating the Global Correlations\n",
    "global_corr=df_encoded[base_metric+metrics].corr(method='spearman').round(3).loc[base_metric,metrics]\n",
    "\n",
    "corridors=df_encoded.groupby(['area','road'])\n",
    "results=[]\n",
    "\n",
    "#iteration every corridor:\n",
    "for (area,road),group in corridors:\n",
    "    local_corr=group[base_metric+metrics].corr(method='spearman').round(3).loc[base_metric,metrics]\n",
    "\n",
    "    #Calculating significant deviations\n",
    "    deviation=local_corr-global_corr\n",
    "    if abs(deviation).max().max() > 0.15:\n",
    "        results.append({\n",
    "            'area':area,\n",
    "            'road':road,\n",
    "            'deviation':deviation})\n",
    "global_corr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df773ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ingestion into a DataFrame by stacking the matrix results\n",
    "final_list=[]\n",
    "\n",
    "for item in results:\n",
    "    area=item['area']\n",
    "    road=item['road']\n",
    "    matrix=item['deviation']\n",
    "\n",
    "    #Stacking the matrix results\n",
    "    df_mid=matrix.stack().reset_index()\n",
    "    df_mid.columns=['Sustainability','metric','deviation']\n",
    "    df_mid['area']=area\n",
    "    df_mid['road']=road\n",
    "\n",
    "    final_list.append(df_mid) #small dfs appending to a list\n",
    "\n",
    "#Final concatenation into single DataFrame:\n",
    "df_final=pd.concat(final_list)\n",
    "df_final=df_final[df_final['deviation'].abs() > 0.15]\n",
    "df_final.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f4f03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Final Multi-Dimensional Corridor Priority score as the analytical summary and priorities of each corridor.\n",
    "#Weightage : 40% mean_congestion, 25% volatility(coeff_of_variation), 15% corridor sensitivity(Maverick Index), 10%(safety), 10%(sustainaibility)\n",
    "\n",
    "base_metric=['congestion_score']\n",
    "metrics=['traffic_volume','avg_speed','ped_cycle_count','incident_reports','environmental_impact']\n",
    "\n",
    "df_encoded=pd.concat([df[['area','road']], df[base_metric+metrics]],axis=1)\n",
    "\n",
    "#Calculating the global correlation:\n",
    "global_corr=df_encoded[base_metric+metrics].corr(method='spearman').round(3).loc[base_metric,metrics]\n",
    "\n",
    "#Calculating the corridor wise metrics\n",
    "corridors=df_encoded.groupby(['area','road'])\n",
    "results=[]\n",
    "\n",
    "for (area,road),group in corridors:\n",
    "    local_corr=group[base_metric+metrics].corr(method='spearman').round(3).loc[base_metric,metrics]\n",
    "    deviation=abs(local_corr-global_corr).round(3)\n",
    "    \n",
    "    df_mid=deviation.stack().reset_index()\n",
    "    df_mid.columns=['base_metric','metric','deviation']\n",
    "    \n",
    "    #Extracting key-metrics for each corridor for calculation of Multi-Dimensional KPI\n",
    "    maverick_index=df_mid['deviation'].mean()\n",
    "    m_cong=group['congestion_score'].mean()\n",
    "    v_cong=group['congestion_score'].std()\n",
    "    safety=group['incident_reports'].mean()\n",
    "    env=group['environmental_impact'].mean()\n",
    "\n",
    "    #Now for each corridor creating a List of dictionary data type elements containing all essential metric data for each corridor\n",
    "    results.append({\n",
    "        'area':area,\n",
    "        'road':road,\n",
    "        'm_cong':m_cong,\n",
    "        'v_cong': v_cong/m_cong if m_cong>0 else 0,\n",
    "        'm_index':maverick_index,\n",
    "        'safety':safety,\n",
    "        'env':env\n",
    "    })\n",
    "\n",
    "df1=pd.DataFrame(results)\n",
    "\n",
    "#Normalize each of our metrics\n",
    "def normalize(s):\n",
    "    return (s-min(s))/(max(s)-min(s))\n",
    "\n",
    "df1['n_cong']=normalize(df1['m_cong']).round(3)\n",
    "df1['n_vol']=normalize(df1['v_cong']).round(3)\n",
    "df1['n_mindex']=normalize(df1['m_index']).round(3)\n",
    "df1['n_safety']=normalize(df1['safety']).round(3)\n",
    "df1['n_env']=normalize(df1['env']).round(3)\n",
    "\n",
    "#Defining the Final Corridor KPI Matrix:\n",
    "df1['priority_score']= (df1['n_cong'] * 0.40 + df1['n_vol'] * 0.25 + df1['n_mindex'] * 0.15 + df1['n_safety'] * 0.10 + df1['n_env'] * 0.10) *100\n",
    "\n",
    "df_final=df1[['area','road','priority_score']]\n",
    "df_final=df_final.sort_values(by=['priority_score'],ascending=False)\n",
    "df_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
